{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "# (a) import and check the data, making sure they are imported as integers.\n",
    "train_data = np.loadtxt(\"/Users/fanyingtang/Desktop/homework_1/project_1/train.csv\",\\\n",
    "                        delimiter=\",\", \\\n",
    "                        skiprows=1, \\\n",
    "                        usecols=range(0,785), \\\n",
    "                        dtype=np.uint64)\n",
    "train_label = np.loadtxt(\"/Users/fanyingtang/Desktop/homework_1/project_1/train.csv\", \\\n",
    "                         delimiter=\",\", \\\n",
    "                         skiprows=1, \\\n",
    "                         usecols = range(0,1), \\\n",
    "                         dtype = np.uint64)\n",
    "\n",
    "digit_label = np.unique(train_label)\n",
    "\n",
    "hei = wid = int(math.sqrt(train_data.shape[1]-1))\n",
    "\n",
    "# (b) Write a function to display an MNIST digit. Display one of each digit.\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "def digit_display(digitlabel, traindata): \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    count = 0\n",
    "    for i in digitlabel:\n",
    "        count = count + 1\n",
    "        digit_pixel = traindata[traindata[:,0] == i][0, 1:].reshape(hei,wid)\n",
    "        ax = plt.subplot(2, 5, count)\n",
    "        ax.set_title('Label is %s'% (i))\n",
    "        ax.imshow(digit_pixel, cmap='gray')\n",
    "    figure=plt.tight_layout()\n",
    "    return figure\n",
    "    \n",
    "\n",
    "digit_display(digit_label, train_data)\n",
    "\n",
    "# (c) \n",
    "# Examine the prior probabality\n",
    "digit_prob_list = []\n",
    "for i in digit_label:\n",
    "    digit_count = train_label.tolist().count(digit_label[i])\n",
    "    digit_prob = digit_count / train_data.shape[0]\n",
    "    digit_prob_list.append(digit_prob)\n",
    "digit_prob_data = {'digit': digit_label, 'prior prob':digit_prob_list}\n",
    "digit_prob_data = pd.DataFrame(data = digit_prob_data)\n",
    "print(digit_prob_data)\n",
    "\n",
    "# plot the histogram\n",
    "plt.hist(train_label, normed=True)\n",
    "plt.title(\"Normalized Histogram of Digital Counts\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "\n",
    "# find the featured vector of the digit to be tested\n",
    "def test_digit(input_data, i):\n",
    "    test = train_data[input_data[:,0] == i][0, 1:]\n",
    "    return test\n",
    "\n",
    "# calculate the Euclidean distance between two digits\n",
    "# sample1 and sample2 are arrays\n",
    "def digit_distance(sample1, sample2):\n",
    "    dist = math.sqrt(sum((sample1 - sample2) ** 2))*1.0\n",
    "    return dist\n",
    "\n",
    "# find the k nearest neighbours\n",
    "# trainingSet, testInstance are arrays. k is an integer.\n",
    "import operator\n",
    "def getNeighbors(trainingSet, testInstance, k):\n",
    "    neighbor_distances = []\n",
    "    for row in trainingSet:\n",
    "        dist = digit_distance(testInstance, row)\n",
    "        neighbor_distances.append((row, dist))\n",
    "        \n",
    "    neighbor_distances.sort(key=operator.itemgetter(1))\n",
    "    neighbors = []\n",
    "    \n",
    "    # avoid pairing with itself by using range(k+1) and removing the first returned item.\n",
    "    for x in range(k+1):\n",
    "        neighbors.append(neighbor_distances[x][0])\n",
    "        \n",
    "    return neighbors[1:]\n",
    "\n",
    "\n",
    "for digit in digit_label: \n",
    "    plt.figure(figsize=(8, 4))\n",
    "    neighbor_array = getNeighbors(trainingSet = train_data[:, 1:], \\\n",
    "                                  testInstance = test_digit(train_data, digit), \\\n",
    "                                  k = 1)\n",
    "    \n",
    "    pixel_test = test_digit(train_data, digit).reshape(28,28)\n",
    "    ax_1 = plt.subplot(1, 2, 1)\n",
    "    ax_1.set_title('The testing data, with label is %s'% (digit))\n",
    "    ax_1.imshow(pixel_test,cmap = 'gray')\n",
    "    \n",
    "    pixel_neighbor = np.array(neighbor_array).reshape(hei,wid)\n",
    "    ax_2 = plt.subplot(1, 2, 2)\n",
    "    ax_2.set_title('The nearest training data, with label = %s'% (digit))\n",
    "    ax_2.imshow(pixel_neighbor,cmap = 'gray')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('nearest_neighbors %s.png' % (digit))\n",
    "    \n",
    "    print(\".\")\n",
    "    \n",
    "# collect all the vectors for digits 0 and 1\n",
    "binary_data = []\n",
    "binary_data_label = []\n",
    "count = 0\n",
    "for i in train_label:\n",
    "    if i == 1 or i == 0:\n",
    "        binary_data.append(train_data[count, 1:])\n",
    "        binary_data_label.append(i)\n",
    "    count = count+1\n",
    "print(len(binary_data), len(binary_data_label))\n",
    "    \n",
    "# calculate the distance between two digits\n",
    "import scipy.spatial\n",
    "from scipy.spatial import distance\n",
    "\n",
    "genuine_distance = []\n",
    "impostor_distance = []\n",
    "bi_dist_mat = scipy.spatial.distance.cdist(binary_data, binary_data, 'euclidean')\n",
    "print(bi_dist_mat.shape)\n",
    "\n",
    "#split into genuine_distance and imposter_distance\n",
    "for i in range(bi_dist_mat.shape[0]):\n",
    "    for j in range(bi_dist_mat.shape[1]):\n",
    "        if i != j:\n",
    "            if binary_data_label[i] == binary_data_label[j]:\n",
    "                genuine_distance.append(bi_dist_mat[i][j])\n",
    "            else:\n",
    "                imposter_distance.append(bi_dist_mat[i][j])\n",
    "            \n",
    "bins = np.linspace(0, 5000, 50)\n",
    "\n",
    "plt.hist(genuine_distance, bins, alpha=0.5, normed = True, label='Genuine Distance')\n",
    "plt.hist(impostor_distance, bins, alpha=0.5, normed = True, label='Impostor Distance')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# ROC curve method 2. Took long for calculation (two for loops)\n",
    "TPR_list = []\n",
    "FPR_list = []\n",
    "#print(np.amax(impostor_distance))\n",
    "\n",
    "genuine_distance_sort = np.sort(genuine_distance)\n",
    "impostor_distance_sort = np.sort(impostor_distance)\n",
    "\n",
    "\n",
    "for i in range(0, len(impostor_distance_sort), int(len(impostor_distance_sort)/100)):\n",
    "    # TPR=TP/(TP+FN)\n",
    "    # FPR=FP/(TN+FP)\n",
    "    TPR = 100*sum(genuine_distance_sort < impostor_distance_sort[i])/float(len(genuine_distance_sort))\n",
    "    TPR_list.append(TPR)\n",
    "    \n",
    "    FPR = 100*sum(impostor_distance_sort < impostor_distance_sort[i])/float(len(impostor_distance_sort))\n",
    "    FPR_list.append(FPR)\n",
    "    \n",
    "    FNR = 100 - TPR\n",
    "    if (int(FNR) == int(FPR)):\n",
    "            print(\"Equal Error: \" + repr(FPR))\n",
    "    \n",
    "#print(len(TPR_list), len(FPR_list))\n",
    "\n",
    "\n",
    "plt.plot(FPR_list, TPR_list)\n",
    "plt.xlabel('FPR_list')\n",
    "plt.ylabel('TPR_list')\n",
    "plt.show()\n",
    "\n",
    "# (g)Implement a K-NN classifier.\n",
    "import operator\n",
    "import scipy.spatial\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def Vote(neighbor_dist, trainingLabel, k):\n",
    "    dist_sorted_index = np.argsort(neighbor_dist)\n",
    "    classVotes = {}\n",
    "    for i in range(k):\n",
    "        vote_index = dist_sorted_index[i]\n",
    "        vote_ind = trainingLabel[vote_index]\n",
    "        if vote_ind in classVotes:\n",
    "            classVotes[vote_ind] +=1\n",
    "        else:\n",
    "            classVotes[vote_ind] = 1        \n",
    "    sortedVotes = sorted(classVotes.items(), key = operator.itemgetter(1), reverse = True)\n",
    "    return sortedVotes[0][0]\n",
    "\n",
    "def KNearestNeighbor(testingSet, trainingSet, trainingLabel, k): \n",
    "    dist_mat = scipy.spatial.distance.cdist(testingSet, trainingSet, 'euclidean')\n",
    "    # the result is a N1*N2 matrix\n",
    "    \n",
    "    predictions = [] \n",
    "    for row in dist_mat:\n",
    "        predictions.append(Vote(row, trainingLabel, k))\n",
    "        \n",
    "    # np.apply_along_axis(Vote(trainingLabel,k), axis=1, arr=dist_mat)\n",
    "    \n",
    "    return(predictions)\n",
    "\n",
    "\n",
    "#(h) Do 3 fold cross validation with k = 3\n",
    "# evaluate accuracy of prediction\n",
    "def getAccuracy(testLabel, predictions):\n",
    "    correct = 0\n",
    "    for x in range(len(testLabel)):\n",
    "        if testLabel[x] == predictions[x]:\n",
    "            correct += 1\n",
    "    accuracy_rate = (correct/float(len(testLabel))) * 100.0\n",
    "    return accuracy_rate\n",
    "\n",
    "# do evaluation on the splitted data for cross validation\n",
    "def evaluate(fold):\n",
    "    train_indices, test_indices = fold\n",
    "    data_train = train_data[:, 1:785][train_indices]\n",
    "    label_train = train_label[train_indices]\n",
    "    data_test = train_data[:, 1:785][test_indices]\n",
    "    label_test = train_label[test_indices]\n",
    "    predictions = KNearestNeighbor(data_test, data_train, label_train, k=3) # get k=3 nearest neighbors\n",
    "    accuracy = getAccuracy(label_test, predictions)\n",
    "    return [accuracy, predictions]\n",
    "\n",
    "from sklearn import cross_validation\n",
    "KNN_results = list(map(evaluate, cross_validation.KFold(len(train_label), 3)))\n",
    "\n",
    "# for 3 fold cross validataion\n",
    "accuracy_total = []\n",
    "for i in range(3): # range is 3 because of 3 fold crossvalidation\n",
    "    accuracy_total.append(KNN_results[i][0])  \n",
    "print(accuracy_total)\n",
    "\n",
    "averange_accuracy = sum(accuracy_total)/len(accuracy_total)\n",
    "float(\"{0:.2f}\".format(averange_accuracy))\n",
    "\n",
    "print(\"The accuracy for k = 9 is %s\"%(float(\"{0:.2f}\".format(averange_accuracy_5)))  )\n",
    "\n",
    "# (i) Generate the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "true_label = train_label\n",
    "predict_label = np.concatenate((KNN_results[0][1], KNN_results[1][1], KNN_results[2][1]), \\\n",
    "                               axis = 0)\n",
    "\n",
    "confustionMatrix = confusion_matrix(true_label, predict_label, labels=[0,1,2,3,4,5,6,7,8,9])\n",
    "print(confustionMatrix)\n",
    "\n",
    "\n",
    "# (j) Do the KNN classification on the test data\n",
    "\n",
    "#import the testing data\n",
    "test_data = np.loadtxt(\"/Users/fanyingtang/Desktop/homework_1/project_1/test.csv\",\\\n",
    "                        delimiter=\",\", \\\n",
    "                        skiprows=1, \\\n",
    "                        usecols=range(0,784), \\\n",
    "                        dtype=np.uint64)\n",
    "prediction_for_test = KNearestNeighbor(test_data, train_data[:,1:785], train_label, k = 3)\n",
    "\n",
    "print(len(prediction_for_test))\n",
    "\n",
    "submit_data = pd.read_csv(\"/Users/fanyingtang/Desktop/homework_1/project_1/sample_submission.csv\")\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"ImageId\": submit_data[\"ImageId\"],\n",
    "        \"Label\": prediction_for_test\n",
    "    })\n",
    "\n",
    "submission.to_csv('sample_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
